{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Question 3: Experimental Investigation\n",
        "\n",
        "In this question, an experimental investigation is conducted to analyse the impact of\n",
        "class imbalance on model performance. The Kepler dataset contains a significantly larger\n",
        "number of non-confirmed detections than confirmed exoplanets, which may bias classifiers\n",
        "towards the majority class. This experiment investigates whether applying class weighting\n",
        "can improve detection of confirmed exoplanets.\n"
      ],
      "metadata": {
        "id": "KEdbGeNGhtFd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYupiUawMK_z",
        "outputId": "cf8fa4e0-dcb0-4b32-fc0e-0117dfb7f7e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'up2115556-machine-learning-and-neural-network-coursework-2'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 60 (delta 19), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 26.05 KiB | 4.34 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "Using Colab cache for faster access to the 'kepler-exoplanet-search-results' dataset.\n"
          ]
        }
      ],
      "source": [
        "import sys, pandas as pd\n",
        "from importlib import reload\n",
        "import kagglehub\n",
        "!rm -rf /content/up2115556-machine-learning-and-neural-network-coursework-2 # ensures a clean cell (this was a massive issue over and over)\n",
        "!git clone https://github.com/up2115556/up2115556-machine-learning-and-neural-network-coursework-2.git #clones the repository\n",
        "sys.path.insert(0, \"/content/up2115556-machine-learning-and-neural-network-coursework-2\")\n",
        "from helpers.functions import prepare_kepler_data, make_train_test_split\n",
        "import helpers.functions as funcs\n",
        "reload(funcs)\n",
        "prepare_kepler_data = funcs.prepare_kepler_data\n",
        "make_train_test_split = funcs.make_train_test_split\n",
        "#downloads the kepler dataset\n",
        "path = kagglehub.dataset_download(\"nasa/kepler-exoplanet-search-results\")\n",
        "df = pd.read_csv(f\"{path}/cumulative.csv\")\n",
        "#preps the data\n",
        "X, y = prepare_kepler_data(df)\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, scaler = make_train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Experimental Setup\n",
        "\n",
        "A Logistic Regression model is used as a baseline and compared against the same model\n",
        "trained with class weighting applied. All preprocessing steps, including feature\n",
        "standardisation and the train test split, are kept identical to ensure a controlled\n",
        "experiment. The only modification is the introduction of class weighting to penalise\n",
        "misclassification of confirmed exoplanets more heavily.\n"
      ],
      "metadata": {
        "id": "oYzLpYzxh3Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# baseline logistic regression model\n",
        "baseline_model = LogisticRegression(max_iter=500)\n",
        "baseline_model.fit(X_train_scaled, y_train)\n",
        "y_pred_base = baseline_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"baseline model\")\n",
        "print(confusion_matrix(y_test, y_pred_base))\n",
        "print(classification_report(y_test, y_pred_base))\n",
        "\n",
        "# logistic regression with class weighting\n",
        "weighted_model = LogisticRegression(\n",
        "    max_iter=500,\n",
        "    class_weight=\"balanced\")\n",
        "weighted_model.fit(X_train_scaled, y_train)\n",
        "y_pred_weighted = weighted_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nweighted model\")\n",
        "print(confusion_matrix(y_test, y_pred_weighted))\n",
        "print(classification_report(y_test, y_pred_weighted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8t8_92iMZKJ",
        "outputId": "470085a2-de42-432f-ae20-bdc7a70aa9f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline model\n",
            "[[1347  107]\n",
            " [  72  387]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.93      0.94      1454\n",
            "         1.0       0.78      0.84      0.81       459\n",
            "\n",
            "    accuracy                           0.91      1913\n",
            "   macro avg       0.87      0.88      0.87      1913\n",
            "weighted avg       0.91      0.91      0.91      1913\n",
            "\n",
            "\n",
            "weighted model\n",
            "[[1271  183]\n",
            " [  24  435]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.87      0.92      1454\n",
            "         1.0       0.70      0.95      0.81       459\n",
            "\n",
            "    accuracy                           0.89      1913\n",
            "   macro avg       0.84      0.91      0.87      1913\n",
            "weighted avg       0.91      0.89      0.90      1913\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results and Discussion\n",
        "\n",
        "Applying class weighting substantially increases recall for confirmed exoplanets,\n",
        "improving detection of real planets and significantly reducing false negatives. This\n",
        "improvement comes at the cost of reduced precision, as the number of false positives\n",
        "increases. These results demonstrate a clear trade off between sensitivity and\n",
        "specificity when addressing class imbalance in binary classification.\n"
      ],
      "metadata": {
        "id": "uaceB43_h94m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "\n",
        "This experiment highlights the importance of addressing class imbalance in exoplanet\n",
        "classification tasks. Class weighting improves sensitivity to confirmed exoplanets,\n",
        "which may be desirable in scientific discovery contexts where missing true positives\n",
        "is costly. However, the increase in false positives underscores the need to balance\n",
        "recall and precision based on application requirements.\n"
      ],
      "metadata": {
        "id": "pJECehCPh_2a"
      }
    }
  ]
}